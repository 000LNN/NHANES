###########################################################1 data extraction###############################################################################
#package
library(haven)
library(nhanesA)
library(tidyverse)
mydata <- read_xpt("e:/nhanes/DEMO_E.XPT")

#document
xuetang <- nhanes('GLU_E')
tanghuadb <- nhanes('GHB_E')
feihuoliang <- nhanes('SPXRAW_E ')

#selec(an example)
xuetang1 <- xuetang  %>% select(SEQN, #serial number
                                LBDGLUSI, #blood glucose（mmol）
                                LBDINSI, #insulin( pmmol/L)
                                PHAFSTHR #postprandial blood sugar)

tanghuadb1<- tanghuadb %>% select(SEQN, # serial number
                                  LBXGH #glycosylated hemoglobin)
feihuoliang1<- feihuoliang %>% select(SEQN, # serial number
                                      SPXNFEV1, #FEV1
                                      SPXNFVC  #FVC，ml)

#merge
hdata<-join_all(list(dat1, xuetang1,tanghuadb1,feihuoliang1), by = 'SEQN', type = 'full')
write.csv(hdata,file = "1.csv",row.names = F)

##################################################2 logistic regression####################################################################################################
mod2 <- glm(MCQ230A~ DMDBORN+INDFMPIR+BMXHT+BMXWAIST+RHQ310+RHQ540,data=NHANES_1999_2006_NA_1,family = binomial(link = 'logit'))
summary(mod2)
exp(cbind(OR = coef(mod2), confint(mod2)))
Loggstic1 <- tbl_regression(mod2, exponentiate=T)
Loggstic1

##################################################3 Multiple Imputation##################################################################################
library(mice) 
data(sleep,package = "VIM") 
imp <- mice(sleep, seed = 1234) 
summary(imp)
imp$imp$Span

dataset2 <- complete(imp, action = 2)
dataset2 #  View the dataset 2

fit=with(imp,lm(Time ~ 	AGE+Sex+Surgery+Grade))
summary(fit)
summary(fit[["analyses"]][[1]])
summary(fit[["analyses"]][[2]])
summary(fit[["analyses"]][[3]])
summary(fit[["analyses"]][[4]])
summary(fit[["analyses"]][[5]])
AIC(fit[["analyses"]][[1]])
AIC(fit[["analyses"]][[2]])
AIC(fit[["analyses"]][[3]])
AIC(fit[["analyses"]][[4]])
AIC(fit[["analyses"]][[5]])
BIC(fit[["analyses"]][[1]])
BIC(fit[["analyses"]][[2]])
BIC(fit[["analyses"]][[3]])
BIC(fit[["analyses"]][[4]])
BIC(fit[["analyses"]][[5]])
anova(fit[["analyses"]][[1]],fit[["analyses"]][[2]])

################################################4 Imbalanced Datasets###########################################################################################
data <- read.csv("C:/Users/Desktop/Gynecological_operation_1999_2020_3_3.CSV")
data$X16_31_2<- as.factor(data$X16_31_2)
set.seed(1234)  
index <-  which( (1:nrow(data))%%3 == 0 )
train <- data[-index,]
test <- data[index,]
summary(train)

prop.table(table(train$X16_31_2))#Check the distribution of Y


library("rpart")
treeimb <- rpart(X16_31_2~ ., data=train)
pred.treeimb <- predict(treeimb, newdata= test)
roc.curve(test$X16_31_2,pred.treeimb[,2], plotit = F)


#1 over-sampling
data.balanced.over <- ovun.sample(X16_31_2 ~., data = train, method = "over",N = 12972,seed = 1)$data
summary(data.balanced.over)
tree.over <- rpart(X16_31_2 ~ ., data =data.balanced.over)
pred.tree.over <- predict(tree.over,newdata = test)
roc.curve(test$X16_31_2,pred.tree.over[,2], plotit = F)

#2 under-sampling
data.balanced.under <- ovun.sample(X16_31_2 ~., data = train, method = "under", N = 16, seed = 1)$data
summary(data.balanced.under)
tree.under <- rpart(X16_31_2 ~ ., data =data.balanced.under)
pred.tree.under <- predict(tree.under,newdata = test)
roc.curve(test$X16_31_2,pred.tree.under[,2], plotit = F)

#3 both
data.balanced.both <- ovun.sample(X16_31_2 ~., data = train, method = "both", p=0.5, N=1000, seed =1)$data
summary(data.balanced.both)
tree.both <- rpart(X16_31_2 ~ ., data =data.balanced.both)
pred.tree.both <- predict(tree.both,newdata = test)
roc.curve(test$X16_31_2,pred.tree.both[,2], plotit = F)
#################################################5 XGBoost###################################################################################
library("xgboost")
library("Matrix")
library("Ckmeans.1d.dp")
library("pROC")

data <- NHANES_2006_2016_2020_1
data$X16_31<- as.factor(data$X16_31)
set.seed(1234)  
index <-  which( (1:nrow(data))%%3 == 0 )
train <- data[-index,]
test <- data[index,]
summary(train)

train_matrix <- sparse.model.matrix(X16_31 ~ .-1, data = train)
test_matrix <- sparse.model.matrix(X16_31 ~ .-1, data = test)
train_label <- as.numeric(train$X16_31)
test_label <-  as.numeric(test$X16_31)
train_fin <- list(data=train_matrix,label=train_label) 
test_fin <- list(data=test_matrix,label=test_label) 
dtrain <- xgb.DMatrix(data = train_fin$data, label = train_fin$label) 
dtest <- xgb.DMatrix(data = test_fin$data, label = test_fin$label)


#
xgb <- xgboost(data = dtrain,max_depth=6, eta=0.5,  
               objective='binary:logistic', nround=25)
#
importance <- xgb.importance(train_matrix@Dimnames[[2]], model = xgb)  
head(importance)
xgb.ggplot.importance(importance)

#
pre_xgb = round(predict(xgb,newdata = dtest))
table(test_label,pre_xgb,dnn=c("true","pre"))
#    pre
#true    0    1
#   0 1633   95
#   1  197  240
#
library("PROC")
xgboost_roc <- roc(test_label,as.numeric(pre_xgb))
plot(xgboost_roc, print.auc=TRUE, auc.polygon=TRUE, 
     grid=c(0.1, 0.2),grid.col=c("green", "red"), 
     max.auc.polygon=TRUE,auc.polygon.col="skyblue", 
     print.thres=TRUE,main='ROC curve')


#################################################6 PAF######################################################################################
library(readxl)
data<- read_excel("C:/Users/Desktop/EXCEL.xlsx")
attach(data)
a<-RR_per_10mmhg^0.1
F1<-function(a,miu1,sigma1,miu2,lowerlimit,higherlimit){return(pnorm((miu2-miu1)/sigma1)-pnorm((lowerlimit-miu1)/sigma1)+a^(miu1-miu2)*exp((sigma1*log(a))^2*0.5)*(pnorm((higherlimit-miu1)/sigma1-sigma1*log(a))-pnorm((miu2-miu1)/sigma1-sigma1*log(a))))}
F2<-function(a,miu2,sigma2,lowerlimit,higherlimit){return(pnorm(0)-pnorm((lowerlimit-miu2)/sigma2)+exp((sigma2*log(a))^2*0.5)*(pnorm((higherlimit-miu2)/sigma2-sigma2*log(a))-pnorm(-sigma2*log(a))))}
PAF<-round((F1(a,miu1,sigma1,miu2,lowerlimit,higherlimit)-F2(a,miu2,sigma2,lowerlimit,higherlimit))/F1(a,miu1,sigma1,miu2,lowerlimit,higherlimit),4)
dataPAF<-cbind(data,PAF)
View(dataPAF)









